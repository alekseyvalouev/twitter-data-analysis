{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c25cd72-eab7-42a7-9afd-643274d0c1be",
   "metadata": {},
   "source": [
    "**All Twitter data used in this notebook was gathered by me.**\n",
    " * See [here.](https://github.com/alekseyvalouev/twitter-data-scraping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40957047-9204-45af-8b1e-6924e554761f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "# Data Structures\n",
    "import numpy  as np\n",
    "import pandas as pd\n",
    "\n",
    "# Language Processing \n",
    "import re\n",
    "import nltk.corpus\n",
    "from unidecode import unidecode\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Analysis\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0674794a-b5e7-483b-9de2-17b275547b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/alekseyvalouev/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Downloads\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50d6012e-45a8-40f9-adef-92c24dedf761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removes stopwords from a tokenized list\n",
    "def remove_stopwords(tokens, words):\n",
    "    return [token for token in tokens if token not in words]\n",
    "\n",
    "# apply stemming to a list of tokens\n",
    "def apply_stemming(tokens, stemmer):\n",
    "    return [stemmer.stem(token) for token in tokens]\n",
    "\n",
    "# apply lemmatization to a list of tokens\n",
    "def apply_lem(tokens, lemmatizer): \n",
    "    return [lemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "# find words <= 2 letters or >= 21 letters\n",
    "def find_two_letters(tokens):\n",
    "    two_letters = []\n",
    "    for token in tokens:\n",
    "        if len(token) <= 2 or len(token) >= 21:\n",
    "            two_letters.append(token)\n",
    "    return two_letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63b35805-ce8c-4ded-84ed-f9115e579ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processCorpus(corpus, language):   \n",
    "    stopwords = nltk.corpus.stopwords.words(language)\n",
    "    param_stemmer = SnowballStemmer(language)\n",
    "    param_lem = WordNetLemmatizer()\n",
    "    \n",
    "    for document in corpus:\n",
    "        index = corpus.index(document)\n",
    "        corpus[index] = corpus[index].replace(u'\\ufffd', '8')   # Replaces the ASCII '�' symbol with '8'\n",
    "        corpus[index] = corpus[index].replace(',', '')          # Removes commas\n",
    "        corpus[index] = corpus[index].rstrip('\\n')              # Removes line breaks\n",
    "        corpus[index] = corpus[index].casefold()                # Makes all letters lowercase\n",
    "        \n",
    "        corpus[index] = re.sub('\\W_',' ', corpus[index])        # removes specials characters and leaves only words\n",
    "        corpus[index] = re.sub(\"\\S*\\d\\S*\",\" \", corpus[index])   # removes numbers and words concatenated with numbers IE h4ck3r. Removes road names such as BR-381.\n",
    "        corpus[index] = re.sub(\"\\S*@\\S*\\s?\",\" \", corpus[index]) # removes emails and mentions (words with @)\n",
    "        corpus[index] = re.sub(r'http\\S+', '', corpus[index])   # removes URLs with http\n",
    "        corpus[index] = re.sub(r'www\\S+', '', corpus[index])    # removes URLs with www\n",
    "\n",
    "        listOfTokens = word_tokenize(corpus[index])\n",
    "        twoLetterWord = find_two_letters(listOfTokens)\n",
    "\n",
    "        listOfTokens = remove_stopwords(listOfTokens, stopwords)\n",
    "        listOfTokens = remove_stopwords(listOfTokens, twoLetterWord)\n",
    "        \n",
    "        listOfTokens = apply_lem(listOfTokens, param_lem)\n",
    "\n",
    "        corpus[index]   = \" \".join(listOfTokens)\n",
    "        corpus[index] = unidecode(corpus[index])\n",
    "\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d755edf-49e0-4b93-a657-8faa06022fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"twitter_data.csv\", lineterminator=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee75c421-4451-4b23-9f5c-f176b14b702a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"Unnamed: 0\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76eb1aeb-723d-4850-b826-3afed36218ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = list(df[\"Text of Tweet\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f11abd24-dff6-492f-a5b3-ed1da90558be",
   "metadata": {},
   "outputs": [],
   "source": [
    "language = 'english'\n",
    "corpus = processCorpus(corpus, language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd3f6b2b-dbe6-49c8-b9fc-af54865dc2f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekseyvalouev/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>__</th>\n",
       "      <th>___</th>\n",
       "      <th>___ ___</th>\n",
       "      <th>___ fill</th>\n",
       "      <th>___ tree</th>\n",
       "      <th>_____</th>\n",
       "      <th>______</th>\n",
       "      <th>______ check</th>\n",
       "      <th>________</th>\n",
       "      <th>________ sunday</th>\n",
       "      <th>...</th>\n",
       "      <th>zynexrocks</th>\n",
       "      <th>zynexrocks zynexexecs</th>\n",
       "      <th>zynexsalesteam</th>\n",
       "      <th>zynexsalesteam endtheopioidepidemic</th>\n",
       "      <th>zynq</th>\n",
       "      <th>zynq rfsoc</th>\n",
       "      <th>zyskind</th>\n",
       "      <th>zyskind production</th>\n",
       "      <th>zyxi</th>\n",
       "      <th>zyxi set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36068</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36069</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36070</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36071</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36072</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36073 rows × 309231 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        __  ___  ___ ___  ___ fill  ___ tree  _____  ______  ______ check  \\\n",
       "0      0.0  0.0      0.0       0.0       0.0    0.0     0.0           0.0   \n",
       "1      0.0  0.0      0.0       0.0       0.0    0.0     0.0           0.0   \n",
       "2      0.0  0.0      0.0       0.0       0.0    0.0     0.0           0.0   \n",
       "3      0.0  0.0      0.0       0.0       0.0    0.0     0.0           0.0   \n",
       "4      0.0  0.0      0.0       0.0       0.0    0.0     0.0           0.0   \n",
       "...    ...  ...      ...       ...       ...    ...     ...           ...   \n",
       "36068  0.0  0.0      0.0       0.0       0.0    0.0     0.0           0.0   \n",
       "36069  0.0  0.0      0.0       0.0       0.0    0.0     0.0           0.0   \n",
       "36070  0.0  0.0      0.0       0.0       0.0    0.0     0.0           0.0   \n",
       "36071  0.0  0.0      0.0       0.0       0.0    0.0     0.0           0.0   \n",
       "36072  0.0  0.0      0.0       0.0       0.0    0.0     0.0           0.0   \n",
       "\n",
       "       ________  ________ sunday  ...  zynexrocks  zynexrocks zynexexecs  \\\n",
       "0           0.0              0.0  ...         0.0                    0.0   \n",
       "1           0.0              0.0  ...         0.0                    0.0   \n",
       "2           0.0              0.0  ...         0.0                    0.0   \n",
       "3           0.0              0.0  ...         0.0                    0.0   \n",
       "4           0.0              0.0  ...         0.0                    0.0   \n",
       "...         ...              ...  ...         ...                    ...   \n",
       "36068       0.0              0.0  ...         0.0                    0.0   \n",
       "36069       0.0              0.0  ...         0.0                    0.0   \n",
       "36070       0.0              0.0  ...         0.0                    0.0   \n",
       "36071       0.0              0.0  ...         0.0                    0.0   \n",
       "36072       0.0              0.0  ...         0.0                    0.0   \n",
       "\n",
       "       zynexsalesteam  zynexsalesteam endtheopioidepidemic  zynq  zynq rfsoc  \\\n",
       "0                 0.0                                  0.0   0.0         0.0   \n",
       "1                 0.0                                  0.0   0.0         0.0   \n",
       "2                 0.0                                  0.0   0.0         0.0   \n",
       "3                 0.0                                  0.0   0.0         0.0   \n",
       "4                 0.0                                  0.0   0.0         0.0   \n",
       "...               ...                                  ...   ...         ...   \n",
       "36068             0.0                                  0.0   0.0         0.0   \n",
       "36069             0.0                                  0.0   0.0         0.0   \n",
       "36070             0.0                                  0.0   0.0         0.0   \n",
       "36071             0.0                                  0.0   0.0         0.0   \n",
       "36072             0.0                                  0.0   0.0         0.0   \n",
       "\n",
       "       zyskind  zyskind production  zyxi  zyxi set  \n",
       "0          0.0                 0.0   0.0       0.0  \n",
       "1          0.0                 0.0   0.0       0.0  \n",
       "2          0.0                 0.0   0.0       0.0  \n",
       "3          0.0                 0.0   0.0       0.0  \n",
       "4          0.0                 0.0   0.0       0.0  \n",
       "...        ...                 ...   ...       ...  \n",
       "36068      0.0                 0.0   0.0       0.0  \n",
       "36069      0.0                 0.0   0.0       0.0  \n",
       "36070      0.0                 0.0   0.0       0.0  \n",
       "36071      0.0                 0.0   0.0       0.0  \n",
       "36072      0.0                 0.0   0.0       0.0  \n",
       "\n",
       "[36073 rows x 309231 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(1,2)) # using unigram and bigram models\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "tf_idf = pd.DataFrame(data = X.toarray(), columns=vectorizer.get_feature_names())\n",
    "\n",
    "tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7ebe1cc-9e7e-41de-b1b5-ed21bd3eb0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_kmeans(k, data):\n",
    "    kmeans = cluster.KMeans(n_clusters = k, init = 'k-means++', n_init = 2, tol = 0.0001, random_state = 1, algorithm = 'full')\n",
    "    return kmeans.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37246203-a64e-475f-b1f8-d50adce0350f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_features_cluster(tf_idf_array, prediction, n_feats):\n",
    "    labels = np.unique(prediction)\n",
    "    dfs = []\n",
    "    for label in labels:\n",
    "        id_temp = np.where(prediction==label) # indices for each cluster\n",
    "        x_means = np.mean(tf_idf_array[id_temp], axis = 0) # returns average score across cluster\n",
    "        sorted_means = np.argsort(x_means)[::-1][:n_feats] # indices with top 20 scores\n",
    "        features = vectorizer.get_feature_names()\n",
    "        best_features = [(features[i], x_means[i]) for i in sorted_means]\n",
    "        df = pd.DataFrame(best_features, columns = ['features', 'score'])\n",
    "        dfs.append(df)\n",
    "    return dfs\n",
    "\n",
    "def plotWords(dfs, n_feats, columns):\n",
    "    plt.rcParams.update({'font.size': 2})\n",
    "    \n",
    "    # Compute Rows required\n",
    "\n",
    "    rows = len(dfs) // columns \n",
    "    rows += len(dfs) % columns\n",
    "\n",
    "    # Create a Position index\n",
    "\n",
    "    Position = range(1, len(dfs) + 1)\n",
    "    \n",
    "    fig = plt.figure(1, dpi=800)\n",
    "    fig.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=0.3, hspace=0.7)\n",
    "    \n",
    "    for i in range(0, len(dfs)):\n",
    "        ax = fig.add_subplot(rows,columns,Position[i])\n",
    "        \n",
    "        ax.set_title((\"Most Common Words in Cluster {}\".format(i)), fontsize=3, fontweight='bold')\n",
    "        \n",
    "        sns.barplot(x = 'score' , y = 'features', orient = 'h' , data = dfs[i][:n_feats])\n",
    "    \n",
    "    plt.savefig('word_freq.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b467b08-b364-4c0a-9700-c139d7a52d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 11\n",
    "kmeans = run_kmeans(k, tf_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962d26bd-5a58-4b36-b9b9-b378bf0a9621",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = kmeans.labels_ \n",
    "df['label'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f096691c-a8a6-41a2-bc08-4e670a0282ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if black borders in figure just run this cell again\n",
    "\n",
    "final_df_array = tf_idf.to_numpy()\n",
    "prediction = data_cleaned['label']\n",
    "n_feats = 20\n",
    "dfs = get_top_features_cluster(final_df_array, prediction, n_feats)\n",
    "plotWords(dfs, 13, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1577f63-8baa-4b17-a13e-85596b2892ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
